# ConstellationÂ ğŸ“¡

**Async Embedding & Vector Search Service for Dome**

---

## 1Â Overview

Constellation is a dedicated CloudflareÂ Worker that:

- **Consumes** rawâ€‘text jobs from a WorkersÂ Queue, turns them into vector
  embeddings with WorkersÂ AI, and upserts them into the shared Vectorize index.
- **Exposes** a **typed RPC interface** (service binding) so any other Worker
  (API, cron importers, CLI) can embed on demand, run vector/text queries, or
  pull quick statsÂ â€”Â without speaking HTTP or knowing the AI/key details.

This removes heavy AI calls from userâ€‘facing code, provides bulkâ€‘loading
capacity (GitHub,Â Notion, â€¦), and gives one central place to evolve our
model/metadata scheme.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         enqueue           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Worker   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  EMBED_QUEUE  â”‚
â”‚  GitHub Cron  â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  Notion Cron  â”‚                                 â–²
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚ batch
        â”‚ service RPC                             â”‚
        â–¼                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Constellation Worker (service â€œembedderâ€)        â”‚
â”‚                                                               â”‚
â”‚   queue(jobs)  â”€â–º  embedBatch()  â”€â–º  WorkersÂ AI  â”€â–º Vectorize â”‚
â”‚                               â–²               â”‚              â”‚
â”‚     RPC: query(), stats()  â”€â”€â”€â”˜               â””â”€â”€â”€â–º logs/metrics
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2Â Goals & Nonâ€‘Goals

|                                                    | âœ” In scope | âœ– Out |
| -------------------------------------------------- | ---------- | ----- |
| Async, highâ€‘throughput ingestion (queue consumer). | âœ”          |       |
| Bulk backâ€‘fills (GitHub repo, Notion export).      | âœ”          |       |
| Single RPC surface (`embed`, `query`, `stats`).    | âœ”          |       |
| Equalityâ€‘filter search on Vectorize metadata.      | âœ”          |       |
| Reâ€‘ranking, summarisation, hybrid BM25 pipelines.  |            | âœ–     |

---

## 3Â Data Contracts

### 3.1Â Queue Message (`EmbedJob`)

```ts
interface EmbedJob {
  userId: string;
  noteId: string;
  text: string; // â‰¤ 8Â kB preferred
  created: number; // ms since epoch
  version: number; // embedding version
}
```

### 3.2Â Vector Metadata (`NoteVectorMeta`)

```ts
{
  userId: string;
  noteId: string;
  createdAt: number; // s since epoch
  version: number;
}
```

Metadata indexes (oneâ€‘time):

```bash
wrangler vectorize create-metadata-index notes_index \
  --property-name userId    --type string
wrangler vectorize create-metadata-index notes_index \
  --property-name noteId    --type string
wrangler vectorize create-metadata-index notes_index \
  --property-name version   --type number
```

---

## 4Â Constellation Worker Implementation

```ts
// src/constellation.ts
import { WorkerEntrypoint } from 'cloudflare:workers';
import type { VectorMetadata } from '../common/types';

export class Constellation extends WorkerEntrypoint {
  /* ---------------- Queue Consumer ---------------- */
  async queue(batch: MessageBatch<EmbedJob>, env: Env) {
    const jobs = batch.messages.map(m => m.body);

    // 1. preprocess text
    const texts = jobs.map(j => preprocess(j.text));

    // 2. embed (20 per call max)
    const resp = await env.AI.run('@cf/baai/bge-small-en-v1.5', { text: texts });
    const vectors = resp.data.map((vec: number[], i: number) => ({
      id: `note:${jobs[i].noteId}`,
      values: vec,
      metadata: {
        userId: jobs[i].userId,
        noteId: jobs[i].noteId,
        createdAt: Math.floor(jobs[i].created / 1000),
        version: jobs[i].version,
      } satisfies VectorMetadata,
    }));
    await env.VECTORIZE.upsert(vectors);
  }

  /* ---------------- RPC Methods ---------------- */
  /** Embed a single note immediately (rare). */
  public async embed(env: Env, job: EmbedJob): Promise<void> {
    await this.queue({ messages: [{ body: job }], retryAll: () => {} } as any, env);
  }

  /** Vector/text similarity search. */
  public async query(env: Env, text: string, filter: Partial<VectorMetadata>, topK = 10) {
    return await env.VECTORIZE.query(text, { topK, filter });
  }

  /** Lightweight health/stat endpoint. */
  public async stats(env: Env) {
    const info = await env.VECTORIZE.info();
    return { vectors: info.vectorCount, dimension: info.dimensions };
  }
}

export default new Constellation();
```

### 4.1Â wrangler.toml (Constellation)

```toml
name = "constellation"
main = "src/constellation.ts"

[[queues.consumers]]
queue = "EMBED_QUEUE"
max_batch_size = 10

vectorize_binding = "VECTORIZE"
ai_binding = "AI"
```

---

## 5Â Caller Workers

### 5.1Â Binding

```toml
[[services]]
binding   = "CONSTELLATION"
service   = "constellation"
environment = "production"
```

### 5.2Â Usage

```ts
// enqueue for async embed
await env.QUEUE.send('EMBED_QUEUE', {
  userId,
  noteId,
  text,
  created: Date.now(),
  version: 1,
} satisfies EmbedJob);

// direct search
const res = await env.CONSTELLATION.query(queryText, { userId }, 10);
```

RPC stubs are statically typed via `Service<typeof Constellation>`.

---

## 6Â Operational Guidelines

| Aspect            | Recommendation                                                                                                        |
| ----------------- | --------------------------------------------------------------------------------------------------------------------- |
| **Throughput**    | One consumer can embed ~300â€“500 jobs/sec; scale by increasing `queues.concurrency` or deploying additional instances. |
| **Backâ€‘pressure** | On AI 429, call `batch.retryAll(delay)` to reâ€‘queue.                                                                  |
| **Monitoring**    | Emit logs: `embed.ms`, `upsert.ms`, queue lag, failures â†’ Cloudflare Logs/Grafana.                                    |
| **DLQ**           | Configure second queue `EMBED_DEAD` and `batch.sendToDeadLetter`.                                                     |
| **Model upgrade** | Bump `version` in jobs; Constellation upserts new vectors under same ID (or new ID with suffix).                      |
| **Local dev**     | `wrangler dev --queue-consumer` for Constellation; producers use `wrangler queues publish`.                           |

---

## 7Â Migration Plan

1. **Deploy Constellation** Worker; verify `/stats` via RPC.
2. Update API & import Workers to **enqueue** instead of inline embed.
3. Replace any Vectorize `fetch` calls with `env.CONSTELLATION.query`.
4. Monitor queue depth; adjust batch size/concurrency.
5. Remove legacy embedding code paths.

---

### TL;DR

- **Constellation** Worker = queue consumer **+** RPC service.
- Producers push `EmbedJob` messages; Constellation batches, embeds, upserts.
- Other Workers call `env.CONSTELLATION.query()` or `.stats()` through native
  service bindingâ€”no HTTP, full type safety.
