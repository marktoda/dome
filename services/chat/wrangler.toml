name = "chat"
main = "src/index.ts"
workers_dev = false
compatibility_date = "2025-04-15"
compatibility_flags = ["nodejs_als"]

# D1 database for checkpointing
[[d1_databases]]
binding = "CHAT_DB"
database_name = "chat-db"
database_id = "81cd6689-95fd-4cee-94ef-a60ef8d62040"

# API keys and secrets (use wrangler secret to set these)
# - wrangler secret put OPENAI_API_KEY

# Deprecated: Workers AI binding - we're now using OpenAI directly via LangChain
# [ai]
# binding = "AI"

# Service bindings
[[services]]
binding = "CONSTELLATION"
service = "constellation"

[[services]]
binding = "SILO"
service = "silo"

# For local development
[dev]
port = 8788

[vars]
VERSION = "0.1.0"
LOG_LEVEL = "debug"
# Default model to use - can be overridden in environment-specific configs
# Options include: GPT_4_TURBO, GPT_3_5_TURBO, LLAMA_3_70B, LLAMA_3_8B
DEFAULT_MODEL_ID = "GPT_4_TURBO"

[env.production]
vars = {
  ENVIRONMENT = "production",
  # Production environment uses GPT-4 Turbo for best quality
  DEFAULT_MODEL_ID = "GPT_4_TURBO"
}

[env.staging]
vars = {
  ENVIRONMENT = "staging",
  # Staging environment can use a more cost-effective model
  DEFAULT_MODEL_ID = "GPT_3_5_TURBO"
}
command = "pnpm build"

[env.development]
vars = {
  ENVIRONMENT = "development",
  # Development environment can use Cloudflare's Llama model to reduce costs
  DEFAULT_MODEL_ID = "LLAMA_3_8B"
}

[observability]
enabled = true
head_sampling_rate = 1
